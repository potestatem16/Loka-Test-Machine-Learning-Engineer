# Loka-Test-Machine-Learning-Engineer

The project involved several key stages, starting from data loading and processing to the final deployment of a Streamlit-based chatbot application. Here's a summary of the entire process:

## Data Loading and Processing:
The initial step involved loading AWS documentation, which was in Markdown format. This data was then processed to transform it into a more structured and readable format. Special attention was given to cleaning and normalizing the text, removing Markdown and HTML tags, and structuring the data into logical sections with relevant metadata tagging.

## Document Indexing with BERT:
A BERT (Bidirectional Encoder Representations from Transformers) model was employed to index the processed documentation. This step was crucial for enabling efficient retrieval of relevant document sections based on user queries. The model's ability to understand natural language made it ideal for this task.

## Semantic Search Implementation:
The indexed data was then used to implement a semantic search function. This function utilized the embeddings generated by the BERT model to find the most relevant sections of the documentation in response to specific queries.

## Integration with LLaMA 2 via Replicate API:
To enhance the chatbot's response quality, the LLaMA 2 model was integrated using the Replicate API. This model was responsible for generating detailed and contextually rich responses based on the input query and the relevant documentation sections identified by the BERT model.

## Building the Chatbot Interface with Streamlit:
A user-friendly chatbot interface was developed using Streamlit. This interface allowed users to input their queries and receive responses generated by the LLaMA 2 model. The chatbot displayed the conversation history and provided options for users to interact with the system effectively.
